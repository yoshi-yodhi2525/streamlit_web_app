import streamlit as st
import pandas as pd
import numpy as np
import networkx as nx
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import plotly.express as px
from sklearn.feature_extraction.text import CountVectorizer
import re
from collections import Counter
import io

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="å…±èµ·ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æ",
    page_icon="ğŸ•¸ï¸",
    layout="wide"
)

# ã‚¿ã‚¤ãƒˆãƒ«
st.title("ğŸ•¸ï¸ å…±èµ·ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æã‚¢ãƒ—ãƒª")
st.markdown("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å…±èµ·ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’å¯è¦–åŒ–ã—ã¾ã™")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
st.sidebar.header("è¨­å®š")
upload_option = st.sidebar.radio(
    "ãƒ‡ãƒ¼ã‚¿ã®é¸æŠæ–¹æ³•",
    ["ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨", "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"]
)

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
@st.cache_data
def load_data(file_path):
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
    try:
        df = pd.read_csv(file_path)
        return df
    except Exception as e:
        st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return None

# ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†
def preprocess_text(text):
    """ãƒ†ã‚­ã‚¹ãƒˆã®å‰å‡¦ç†"""
    if pd.isna(text):
        return ""
    text = str(text).lower()
    # ç‰¹æ®Šæ–‡å­—ã‚’é™¤å»
    text = re.sub(r'[^\w\s]', '', text)
    return text

# å…±èµ·è¡Œåˆ—ã®ä½œæˆ
def create_cooccurrence_matrix(texts, min_freq=2, max_features=50):
    """å…±èµ·è¡Œåˆ—ã‚’ä½œæˆ"""
    # ãƒ†ã‚­ã‚¹ãƒˆã®å‰å‡¦ç†
    processed_texts = [preprocess_text(text) for text in texts]
    
    # CountVectorizerã§å˜èªã‚’æŠ½å‡º
    vectorizer = CountVectorizer(
        max_features=max_features,
        min_df=min_freq,
        stop_words=None,
        token_pattern=r'\b\w+\b'
    )
    
    try:
        # å˜èª-æ–‡æ›¸è¡Œåˆ—ã‚’ä½œæˆ
        word_doc_matrix = vectorizer.fit_transform(processed_texts)
        feature_names = vectorizer.get_feature_names_out()
        
        # å…±èµ·è¡Œåˆ—ã‚’è¨ˆç®—
        cooccurrence_matrix = word_doc_matrix.T @ word_doc_matrix
        
        return cooccurrence_matrix.toarray(), feature_names
    except Exception as e:
        st.error(f"å…±èµ·è¡Œåˆ—ã®ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
        return None, None

# ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚°ãƒ©ãƒ•ã®ä½œæˆ
def create_network_graph(cooccurrence_matrix, feature_names, min_weight=1):
    """NetworkXã‚°ãƒ©ãƒ•ã‚’ä½œæˆ"""
    G = nx.Graph()
    
    # ãƒãƒ¼ãƒ‰ã‚’è¿½åŠ 
    for i, word in enumerate(feature_names):
        G.add_node(word, size=cooccurrence_matrix[i, i])
    
    # ã‚¨ãƒƒã‚¸ã‚’è¿½åŠ 
    for i in range(len(feature_names)):
        for j in range(i+1, len(feature_names)):
            weight = cooccurrence_matrix[i, j]
            if weight >= min_weight:
                G.add_edge(feature_names[i], feature_names[j], weight=weight)
    
    return G

# Plotlyã§ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’å¯è¦–åŒ–
def plot_network(G, title="å…±èµ·ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯"):
    """Plotlyã§ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’å¯è¦–åŒ–"""
    if len(G.nodes()) == 0:
        st.warning("ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«ãƒãƒ¼ãƒ‰ãŒã‚ã‚Šã¾ã›ã‚“ã€‚è¨­å®šã‚’èª¿æ•´ã—ã¦ãã ã•ã„ã€‚")
        return None
    
    # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã®è¨ˆç®—
    pos = nx.spring_layout(G, k=1, iterations=50)
    
    # ãƒãƒ¼ãƒ‰ã®åº§æ¨™
    node_x = []
    node_y = []
    node_text = []
    node_size = []
    
    for node in G.nodes():
        x, y = pos[node]
        node_x.append(x)
        node_y.append(y)
        node_text.append(f"{node}<br>å‡ºç¾å›æ•°: {G.nodes[node]['size']}")
        node_size.append(G.nodes[node]['size'])
    
    # ã‚¨ãƒƒã‚¸ã®åº§æ¨™
    edge_x = []
    edge_y = []
    edge_weights = []
    
    for edge in G.edges():
        x0, y0 = pos[edge[0]]
        x1, y1 = pos[edge[1]]
        edge_x.extend([x0, x1, None])
        edge_y.extend([y0, y1, None])
        edge_weights.append(G.edges[edge]['weight'])
    
    # ãƒãƒ¼ãƒ‰ã‚µã‚¤ã‚ºã®æ­£è¦åŒ–
    max_size = max(node_size) if node_size else 1
    node_size = [size / max_size * 20 + 10 for size in node_size]
    
    # ã‚¨ãƒƒã‚¸ã®å¤ªã•ã®æ­£è¦åŒ–
    max_weight = max(edge_weights) if edge_weights else 1
    edge_width = [weight / max_weight * 3 + 1 for weight in edge_weights]
    
    # ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ
    fig = go.Figure()
    
    # ã‚¨ãƒƒã‚¸ã‚’è¿½åŠ 
    for i in range(0, len(edge_x), 3):
        if i + 2 < len(edge_x):
            fig.add_trace(go.Scatter(
                x=[edge_x[i], edge_x[i+1]],
                y=[edge_y[i], edge_y[i+1]],
                mode='lines',
                line=dict(width=edge_width[i//3], color='gray'),
                opacity=0.6,
                hoverinfo='skip',
                showlegend=False
            ))
    
    # ãƒãƒ¼ãƒ‰ã‚’è¿½åŠ 
    fig.add_trace(go.Scatter(
        x=node_x,
        y=node_y,
        mode='markers+text',
        marker=dict(
            size=node_size,
            color='lightblue',
            line=dict(width=2, color='darkblue')
        ),
        text=[name[:10] for name in G.nodes()],
        textposition="middle center",
        hovertext=node_text,
        hoverinfo='text',
        name='ãƒãƒ¼ãƒ‰'
    ))
    
    # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè¨­å®š
    fig.update_layout(
        title=title,
        showlegend=False,
        hovermode='closest',
        margin=dict(b=20, l=5, r=5, t=40),
        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
        plot_bgcolor='white'
    )
    
    return fig

# ãƒ¡ã‚¤ãƒ³å‡¦ç†
def main():
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    if upload_option == "ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨":
        # ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨
        sample_files = ["sample.csv", "text.csv"]
        selected_file = st.sidebar.selectbox("ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ", sample_files)
        file_path = f"x/{selected_file}"
        df = load_data(file_path)
    else:
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        uploaded_file = st.sidebar.file_uploader(
            "CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
            type=['csv']
        )
        if uploaded_file is not None:
            df = pd.read_csv(uploaded_file)
        else:
            st.info("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
            return
    
    if df is None or df.empty:
        st.error("ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸ")
        return
    
    # ãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¤º
    st.subheader("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
    st.dataframe(df.head())
    
    # ãƒ†ã‚­ã‚¹ãƒˆåˆ—ã®é¸æŠ
    text_columns = df.select_dtypes(include=['object']).columns.tolist()
    if not text_columns:
        st.error("ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
    
    selected_column = st.sidebar.selectbox("åˆ†æã™ã‚‹åˆ—ã‚’é¸æŠ", text_columns)
    
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
    col1, col2, col3 = st.sidebar.columns(3)
    with col1:
        min_freq = st.number_input("æœ€å°å‡ºç¾å›æ•°", min_value=1, value=2)
    with col2:
        max_features = st.number_input("æœ€å¤§å˜èªæ•°", min_value=10, value=30)
    with col3:
        min_weight = st.number_input("æœ€å°å…±èµ·é‡ã¿", min_value=1, value=1)
    
    # åˆ†æå®Ÿè¡Œ
    if st.sidebar.button("åˆ†æå®Ÿè¡Œ", type="primary"):
        with st.spinner("å…±èµ·ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆ†æä¸­..."):
            # ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            texts = df[selected_column].dropna().tolist()
            
            if not texts:
                st.error("ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                return
            
            # å…±èµ·è¡Œåˆ—ã‚’ä½œæˆ
            cooccurrence_matrix, feature_names = create_cooccurrence_matrix(
                texts, min_freq, max_features
            )
            
            if cooccurrence_matrix is None:
                return
            
            # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ
            G = create_network_graph(cooccurrence_matrix, feature_names, min_weight)
            
            if len(G.nodes()) == 0:
                st.warning("æ¡ä»¶ã«åˆã†ãƒãƒ¼ãƒ‰ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª¿æ•´ã—ã¦ãã ã•ã„ã€‚")
                return
            
            # çµæœè¡¨ç¤º
            st.subheader("ğŸ•¸ï¸ å…±èµ·ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯")
            
            # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å›³ã‚’è¡¨ç¤º
            fig = plot_network(G, f"{selected_column}ã®å…±èµ·ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯")
            if fig:
                st.plotly_chart(fig, use_container_width=True)
            
            # çµ±è¨ˆæƒ…å ±
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("ãƒãƒ¼ãƒ‰æ•°", len(G.nodes()))
            with col2:
                st.metric("ã‚¨ãƒƒã‚¸æ•°", len(G.edges()))
            with col3:
                density = nx.density(G)
                st.metric("å¯†åº¦", f"{density:.3f}")
            with col4:
                if len(G.nodes()) > 1:
                    avg_degree = sum(dict(G.degree()).values()) / len(G.nodes())
                    st.metric("å¹³å‡æ¬¡æ•°", f"{avg_degree:.1f}")
            
            # è©³ç´°æƒ…å ±
            st.subheader("ğŸ“ˆ è©³ç´°æƒ…å ±")
            
            # ãƒãƒ¼ãƒ‰ã®æ¬¡æ•°ãƒ©ãƒ³ã‚­ãƒ³ã‚°
            degree_ranking = sorted(G.degree(), key=lambda x: x[1], reverse=True)
            degree_df = pd.DataFrame(degree_ranking, columns=['å˜èª', 'æ¬¡æ•°'])
            
            col1, col2 = st.columns(2)
            with col1:
                st.write("**æ¬¡æ•°ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆä¸Šä½10ä½ï¼‰**")
                st.dataframe(degree_df.head(10))
            
            # ã‚¨ãƒƒã‚¸ã®é‡ã¿ãƒ©ãƒ³ã‚­ãƒ³ã‚°
            edge_weights = [(u, v, d['weight']) for u, v, d in G.edges(data=True)]
            edge_weights.sort(key=lambda x: x[2], reverse=True)
            edge_df = pd.DataFrame(edge_weights, columns=['å˜èª1', 'å˜èª2', 'å…±èµ·å›æ•°'])
            
            with col2:
                st.write("**å…±èµ·å¼·åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆä¸Šä½10ä½ï¼‰**")
                st.dataframe(edge_df.head(10))
            
            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½
            st.subheader("ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
            
            # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            network_data = []
            for node in G.nodes():
                network_data.append({
                    'node': node,
                    'degree': G.degree(node),
                    'size': G.nodes[node]['size']
                })
            
            network_df = pd.DataFrame(network_data)
            csv = network_df.to_csv(index=False)
            st.download_button(
                label="ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=csv,
                file_name="network_data.csv",
                mime="text/csv"
            )

if __name__ == "__main__":
    main() 